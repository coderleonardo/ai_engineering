{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:53:12.934495Z","iopub.execute_input":"2025-02-05T09:53:12.934891Z","iopub.status.idle":"2025-02-05T09:53:12.939967Z","shell.execute_reply.started":"2025-02-05T09:53:12.934856Z","shell.execute_reply":"2025-02-05T09:53:12.938938Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -q tensorflow==2.14.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:53:12.941428Z","iopub.execute_input":"2025-02-05T09:53:12.941721Z","iopub.status.idle":"2025-02-05T09:54:47.595475Z","shell.execute_reply.started":"2025-02-05T09:53:12.941688Z","shell.execute_reply":"2025-02-05T09:54:47.594315Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.14.0 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.14.0 which is incompatible.\ntensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q transformers==4.35.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:54:47.597297Z","iopub.execute_input":"2025-02-05T09:54:47.597591Z","iopub.status.idle":"2025-02-05T09:55:01.673059Z","shell.execute_reply.started":"2025-02-05T09:54:47.597564Z","shell.execute_reply":"2025-02-05T09:55:01.672099Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.35.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:55:01.674660Z","iopub.execute_input":"2025-02-05T09:55:01.674924Z","iopub.status.idle":"2025-02-05T09:55:01.679511Z","shell.execute_reply.started":"2025-02-05T09:55:01.674900Z","shell.execute_reply":"2025-02-05T09:55:01.678320Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:55:01.680600Z","iopub.execute_input":"2025-02-05T09:55:01.680830Z","iopub.status.idle":"2025-02-05T09:55:14.934623Z","shell.execute_reply.started":"2025-02-05T09:55:01.680810Z","shell.execute_reply":"2025-02-05T09:55:14.933573Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ef7be2c15d44180af7bad350bc42f5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9de7a8f62d84754b232b5ea7acea6b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d028463e911e4f48abfd492554630b2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbe05772a0c644a0b38de32feb9c05a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9ca3acf0b940da8a4c69dcc530f97b"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:55:14.935532Z","iopub.execute_input":"2025-02-05T09:55:14.935790Z","iopub.status.idle":"2025-02-05T09:55:14.941337Z","shell.execute_reply.started":"2025-02-05T09:55:14.935768Z","shell.execute_reply":"2025-02-05T09:55:14.940389Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"GPT2Tokenizer(name_or_path='gpt2-large', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:55:14.942138Z","iopub.execute_input":"2025-02-05T09:55:14.942349Z","iopub.status.idle":"2025-02-05T09:55:35.736798Z","shell.execute_reply.started":"2025-02-05T09:55:14.942330Z","shell.execute_reply":"2025-02-05T09:55:35.736017Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc1f2d3fada4d27b7fd7f7962409ccb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15257b47bfaa4cb2805b5d8f53bf7625"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:55:35.737750Z","iopub.execute_input":"2025-02-05T09:55:35.737970Z","iopub.status.idle":"2025-02-05T09:55:35.745276Z","shell.execute_reply.started":"2025-02-05T09:55:35.737952Z","shell.execute_reply":"2025-02-05T09:55:35.744201Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 1280)\n    (wpe): Embedding(1024, 1280)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-35): 36 x GPT2Block(\n        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=3840, nx=1280)\n          (c_proj): Conv1D(nf=1280, nx=1280)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=5120, nx=1280)\n          (c_proj): Conv1D(nf=1280, nx=5120)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def prepare_prompt(prompt, tokenizer=tokenizer):\n    return tokenizer.encode(prompt, return_tensors=\"pt\") # input_ids (convert prompt to tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:55:35.749849Z","iopub.execute_input":"2025-02-05T09:55:35.750201Z","iopub.status.idle":"2025-02-05T09:55:37.841688Z","shell.execute_reply.started":"2025-02-05T09:55:35.750166Z","shell.execute_reply":"2025-02-05T09:55:37.840726Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"input_ids = prepare_prompt(\"What is Artificial Inteligence?\", tokenizer)\ninput_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:57:34.718192Z","iopub.execute_input":"2025-02-05T09:57:34.718618Z","iopub.status.idle":"2025-02-05T09:57:34.744623Z","shell.execute_reply.started":"2025-02-05T09:57:34.718586Z","shell.execute_reply":"2025-02-05T09:57:34.743764Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([[ 2061,   318, 35941,  8180,   328,   594,    30]])"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def generate_text(input_ids, model):\n    return model.generate(\n        input_ids, \n        max_length=100, \n        num_beams=5, \n        no_repeat_ngram_size=2, \n        early_stopping=True\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:59:13.316191Z","iopub.execute_input":"2025-02-05T09:59:13.316569Z","iopub.status.idle":"2025-02-05T09:59:13.321014Z","shell.execute_reply.started":"2025-02-05T09:59:13.316540Z","shell.execute_reply":"2025-02-05T09:59:13.319908Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"text = generate_text(input_ids, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:59:31.954612Z","iopub.execute_input":"2025-02-05T09:59:31.954890Z","iopub.status.idle":"2025-02-05T10:00:12.405157Z","shell.execute_reply.started":"2025-02-05T09:59:31.954869Z","shell.execute_reply":"2025-02-05T10:00:12.404160Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:02.029379Z","iopub.execute_input":"2025-02-05T10:02:02.029718Z","iopub.status.idle":"2025-02-05T10:02:02.036152Z","shell.execute_reply.started":"2025-02-05T10:02:02.029691Z","shell.execute_reply":"2025-02-05T10:02:02.035392Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"tensor([[ 2061,   318, 35941,  8180,   328,   594,    30,   198,   198,  8001,\n          9542,  4430,   357, 20185,     8,   318,   257,  8478,   286,  3644,\n          3783,   326,  3544, 11666,  4430,  7605,   284,  8494,  2761,   326,\n           389,  3675,   262,  9889,   286,   262,  1692,  2000,    13,  9552,\n           468,   587,  1088,   329,   257,   890,   640,    11,   475,   340,\n           373,   691,   287,   262,  1613,  1178,   812,   326,   340,   468,\n          1716,   257,  1688,  2962,   286,  2267,   290,  2478,    13, 35941,\n          4430,   468,   262,  2785,   284,  5854,  1096,   262,   835,   356,\n          2107,    11,   670,    11,   290,   711,    13,   632,   460,   635,\n           307,   973,   284,   787,   262,   995,   257,  1365,  1295,    13]])"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"text.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:04:19.008165Z","iopub.execute_input":"2025-02-05T10:04:19.008506Z","iopub.status.idle":"2025-02-05T10:04:19.013592Z","shell.execute_reply.started":"2025-02-05T10:04:19.008479Z","shell.execute_reply":"2025-02-05T10:04:19.012880Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 100])"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"print( tokenizer.decode(text[0], skip_special_tokens=True) )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:04:40.654405Z","iopub.execute_input":"2025-02-05T10:04:40.654932Z","iopub.status.idle":"2025-02-05T10:04:40.661199Z","shell.execute_reply.started":"2025-02-05T10:04:40.654900Z","shell.execute_reply":"2025-02-05T10:04:40.660420Z"}},"outputs":[{"name":"stdout","text":"What is Artificial Inteligence?\n\nArtificial intelligence (AI) is a branch of computer science that uses artificial intelligence techniques to solve problems that are beyond the capabilities of the human mind. AI has been around for a long time, but it was only in the past few years that it has become a major focus of research and development. Artificial intelligence has the potential to revolutionize the way we live, work, and play. It can also be used to make the world a better place.\n","output_type":"stream"}],"execution_count":16}]}