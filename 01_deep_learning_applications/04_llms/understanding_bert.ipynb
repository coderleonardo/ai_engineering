{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"data.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Olá, como vai? Eu sou a Camila.\\n'\n",
      "'Olá, Camila, meu nome é Fernando. Muito prazer.\\n'\n",
      "'Prazer em conhecer você também. Como você está hoje?\\n'\n",
      "'Ótimo. Meu time de futebol venceu a competição.\\n'\n",
      "'Uau, Parabéns Fernando!\\n'\n",
      "'Obrigado Camila.\\n'\n",
      "'Vamos comer uma pizza mais tarde para celebrar?\\n'\n",
      "'Claro. Você recomenda algum restaurante Camila?\\n'\n",
      "'Sim, abriu um restaurante novo e dizem que a pizza de banana é fenomenal.\\n'\n",
      "'Ok. Nos encontramos no restaurante às sete da noite, pode ser?\\n'\n",
      "'Pode sim. Nos vemos mais tarde então.'\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['olá como vai eu sou a camila', 'olá camila meu nome é fernando muito prazer', 'prazer em conhecer você também como você está hoje', 'ótimo meu time de futebol venceu a competição', 'uau parabéns fernando', 'obrigado camila', 'vamos comer uma pizza mais tarde para celebrar', 'claro você recomenda algum restaurante camila', 'sim abriu um restaurante novo e dizem que a pizza de banana é fenomenal', 'ok nos encontramos no restaurante às sete da noite pode ser', 'pode sim nos vemos mais tarde então']\n"
     ]
    }
   ],
   "source": [
    "# re.sub(...) function replaces all occurrences of the characters within the character class with an empty string\n",
    "sentences = re.sub(\"[.,!?\\\\-']\", '', data.lower().replace(\"\\n\", \" \")).split('\\\\n')\n",
    "sentences = [s.strip() for s in sentences]\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['novo', 'então', 'muito', 'ok', 'mais', 'vai', 'time', 'você', 'tarde', 'sim', 'é', 'hoje', 'nome', 'meu', 'obrigado', 'abriu', 'que', 'camila', 'sete', 'ótimo', 'conhecer', 'como', 'olá', 'pode', 'venceu', 'recomenda', 'nos', 'uau', 'algum', 'de', 'sou', 'encontramos', 'restaurante', 'futebol', 'comer', 'claro', 'uma', 'parabéns', 'também', 'celebrar', 'a', 'ser', 'um', 'banana', 'eu', 'pizza', 'dizem', 'em', 'fernando', 'às', 'vamos', 'noite', 'fenomenal', 'vemos', 'está', 'no', 'da', 'prazer', 'competição', 'para', 'e']\n"
     ]
    }
   ],
   "source": [
    "words_lst = list( set( \" \".join(sentences).split() ) )\n",
    "\n",
    "print(words_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT special tokens\n",
    "words_dict = {\n",
    "    \"[PAD]\": 0, \n",
    "    \"[CLS]\": 1, \n",
    "    \"[SEP]\": 2, \n",
    "    \"[MASK]\": 3\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(words_lst):\n",
    "    words_dict[w] = i + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'novo': 4, 'então': 5, 'muito': 6, 'ok': 7, 'mais': 8, 'vai': 9, 'time': 10, 'você': 11, 'tarde': 12, 'sim': 13, 'é': 14, 'hoje': 15, 'nome': 16, 'meu': 17, 'obrigado': 18, 'abriu': 19, 'que': 20, 'camila': 21, 'sete': 22, 'ótimo': 23, 'conhecer': 24, 'como': 25, 'olá': 26, 'pode': 27, 'venceu': 28, 'recomenda': 29, 'nos': 30, 'uau': 31, 'algum': 32, 'de': 33, 'sou': 34, 'encontramos': 35, 'restaurante': 36, 'futebol': 37, 'comer': 38, 'claro': 39, 'uma': 40, 'parabéns': 41, 'também': 42, 'celebrar': 43, 'a': 44, 'ser': 45, 'um': 46, 'banana': 47, 'eu': 48, 'pizza': 49, 'dizem': 50, 'em': 51, 'fernando': 52, 'às': 53, 'vamos': 54, 'noite': 55, 'fenomenal': 56, 'vemos': 57, 'está': 58, 'no': 59, 'da': 60, 'prazer': 61, 'competição': 62, 'para': 63, 'e': 64}\n"
     ]
    }
   ],
   "source": [
    "print(words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'novo', 5: 'então', 6: 'muito', 7: 'ok', 8: 'mais', 9: 'vai', 10: 'time', 11: 'você', 12: 'tarde', 13: 'sim', 14: 'é', 15: 'hoje', 16: 'nome', 17: 'meu', 18: 'obrigado', 19: 'abriu', 20: 'que', 21: 'camila', 22: 'sete', 23: 'ótimo', 24: 'conhecer', 25: 'como', 26: 'olá', 27: 'pode', 28: 'venceu', 29: 'recomenda', 30: 'nos', 31: 'uau', 32: 'algum', 33: 'de', 34: 'sou', 35: 'encontramos', 36: 'restaurante', 37: 'futebol', 38: 'comer', 39: 'claro', 40: 'uma', 41: 'parabéns', 42: 'também', 43: 'celebrar', 44: 'a', 45: 'ser', 46: 'um', 47: 'banana', 48: 'eu', 49: 'pizza', 50: 'dizem', 51: 'em', 52: 'fernando', 53: 'às', 54: 'vamos', 55: 'noite', 56: 'fenomenal', 57: 'vemos', 58: 'está', 59: 'no', 60: 'da', 61: 'prazer', 62: 'competição', 63: 'para', 64: 'e'}\n"
     ]
    }
   ],
   "source": [
    "nums_dict = { i: k for k, i in words_dict.items()}\n",
    "\n",
    "print(nums_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(words_dict)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olá', 'como', 'vai', 'eu', 'sou', 'a', 'camila']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lst = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = [words_dict[s] for s in sentence.split()]\n",
    "    tokens_lst.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 25, 9, 48, 34, 44, 21],\n",
       " [26, 21, 17, 16, 14, 52, 6, 61],\n",
       " [61, 51, 24, 11, 42, 25, 11, 58, 15],\n",
       " [23, 17, 10, 33, 37, 28, 44, 62],\n",
       " [31, 41, 52],\n",
       " [18, 21],\n",
       " [54, 38, 40, 49, 8, 12, 63, 43],\n",
       " [39, 11, 29, 32, 36, 21],\n",
       " [13, 19, 46, 36, 4, 64, 50, 20, 44, 49, 33, 47, 14, 56],\n",
       " [7, 30, 35, 59, 36, 53, 22, 60, 55, 27, 45],\n",
       " [27, 13, 30, 57, 8, 12, 5]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparams definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "N_SEGMENTS = 2\n",
    "DROPOUT    = 0.2\n",
    "\n",
    "MAX_LEN     = 100\n",
    "MAX_PRED    = 7 # max num of tokens that will be predicted \n",
    "\n",
    "N_LAYERS    = 6\n",
    "N_HEADS     = 12\n",
    "\n",
    "D_MODEL     = 768 # embedding dim\n",
    "D_FF        = D_MODEL * 4 # feedforward dim\n",
    "D_K = D_V   = 64\n",
    "\n",
    "N_EPOCHS    = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olá como vai eu sou a camila',\n",
       " 'olá camila meu nome é fernando muito prazer',\n",
       " 'prazer em conhecer você também como você está hoje',\n",
       " 'ótimo meu time de futebol venceu a competição',\n",
       " 'uau parabéns fernando',\n",
       " 'obrigado camila',\n",
       " 'vamos comer uma pizza mais tarde para celebrar',\n",
       " 'claro você recomenda algum restaurante camila',\n",
       " 'sim abriu um restaurante novo e dizem que a pizza de banana é fenomenal',\n",
       " 'ok nos encontramos no restaurante às sete da noite pode ser',\n",
       " 'pode sim nos vemos mais tarde então']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = randrange(len(sentences)), randrange(len(sentences))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([7, 30, 35, 59, 36, 53, 22, 60, 55, 27, 45], [26, 25, 9, 48, 34, 44, 21])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa, bb = tokens_lst[a], tokens_lst[b]\n",
    "aa, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 7, 30, 35, 59, 36, 53, 22, 60, 55, 27, 45, 2, 26, 25, 9, 48, 34, 44, 21, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = [words_dict[\"[CLS]\"]] + aa + [words_dict[\"[SEP]\"]] + bb + [words_dict[\"[SEP]\"]]\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_ids = [0] * (1 + len(aa) + 1) + [1] * (len(bb) + 1)\n",
    "segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(MAX_PRED, max(1, int(round(len(input_ids) * 0.15)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_position_candidates = [i for i, token in enumerate(input_ids) if token != words_dict[\"[CLS]\"] and token != words_dict[\"[SEP]\"]]\n",
    "mask_position_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(batch_size, sentences, tokenized_sentences, word_to_num_dict, num_to_word_dict, max_predictable_tokens, vocab_size, max_len):\n",
    "\n",
    "    batch = []\n",
    "    \n",
    "    positive = negative = 0\n",
    "\n",
    "    while (positive != batch_size/2) or (negative != batch_size/2):\n",
    "\n",
    "        tokens_a_index, tokens_b_index = randrange(len(sentences)), randrange(len(sentences))\n",
    "        tokens_a, tokens_b = tokenized_sentences[tokens_a_index], tokenized_sentences[tokens_b_index]\n",
    "\n",
    "        input_ids = [word_to_num_dict[\"[CLS]\"]] + tokens_a + [word_to_num_dict[\"[SEP]\"]] + tokens_b + [word_to_num_dict[\"[SEP]\"]]\n",
    "        segment_ids = segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        n_pred =  min(max_predictable_tokens, max(1, int(round(len(input_ids) * 0.15)))) \n",
    "\n",
    "        mask_position_candidates = [i for i, token in enumerate(input_ids) if token != word_to_num_dict[\"[CLS]\"] and token != word_to_num_dict[\"[SEP]\"]]\n",
    "        shuffle(mask_position_candidates)\n",
    "\n",
    "        masked_tokens, masked_positions = [], []\n",
    "        for pos in mask_position_candidates[:n_pred]:\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            masked_positions.append(pos)\n",
    "            \n",
    "            if random() < 0.8:\n",
    "                input_ids[pos] = word_to_num_dict[\"[MASK]\"]\n",
    "            elif random() < 0.5:\n",
    "                index = randint(0, vocab_size - 1)\n",
    "                input_ids[pos] = word_to_num_dict[num_to_word_dict[index]]\n",
    "\n",
    "        padding = max_len - len(input_ids)\n",
    "        input_ids.extend([0] * padding)\n",
    "        segment_ids.extend([0] * padding)\n",
    "\n",
    "        if max_predictable_tokens > n_pred:\n",
    "            padding = max_predictable_tokens - n_pred\n",
    "            masked_tokens.extend([0] * padding)\n",
    "            masked_positions.extend([0] * padding) \n",
    "\n",
    "        if (tokens_a_index + 1 == tokens_b_index) and (positive < batch_size / 2):\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_positions, True])\n",
    "            positive += 1\n",
    "\n",
    "        elif (tokens_a_index + 1 != tokens_b_index) and (negative < batch_size / 2):\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_positions, False])\n",
    "            negative += 1\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 6\n",
    "# N_SEGMENTS = 2\n",
    "# DROPOUT    = 0.2\n",
    "\n",
    "# MAX_LEN     = 100\n",
    "# MAX_PRED    = 7 # max num of tokens that will be predicted \n",
    "\n",
    "# N_LAYERS    = 6\n",
    "# N_HEADS     = 12\n",
    "\n",
    "# D_MODEL     = 768 # embedding dim\n",
    "# D_FF        = D_MODEL * 4 # feedforward dim\n",
    "# D_K = D_V   = 64\n",
    "\n",
    "# N_EPOCHS    = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "\n",
    "# d1 = OrderedDict(sorted(nums_dict.items()))\n",
    "# print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = create_batches(batch_size=BATCH_SIZE, \n",
    "                       sentences=sentences, \n",
    "                       tokenized_sentences=tokens_lst, \n",
    "                       word_to_num_dict=words_dict, \n",
    "                       num_to_word_dict=nums_dict, \n",
    "                       max_predictable_tokens=MAX_PRED, \n",
    "                       vocab_size=VOCAB_SIZE, \n",
    "                       max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_positions, is_next = map(torch.LongTensor, zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 54, 38, 40, 49,  8,  3,  3, 43,  2, 39, 11, 29, 32, 36, 21,  2,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([38, 12, 63,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 7, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_next[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_pad_masked(query_sequence, key_sequence):\n",
    "    \n",
    "    batch_size, len_q = query_sequence.size()\n",
    "    batch_size, len_k = key_sequence.size()\n",
    "    \n",
    "    pad_attn_masked = key_sequence.data.eq(0).unsqueeze(1)\n",
    "    \n",
    "    return pad_attn_masked.expand(batch_size, len_q, len_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 54, 38, 40, 49,  8,  3,  3, 43,  2, 39, 11, 29, 32, 36, 21,  2,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attention_pad_masked(input_ids, input_ids)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len, n_segments):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        # print(\"...forward step\")\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)\n",
    "\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "max_len = 100\n",
    "n_segments = 2\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, d_model, max_len, n_segments)\n",
    "\n",
    "# Input example\n",
    "batch_size = 32\n",
    "seq_len = 20\n",
    "x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "seg = torch.randint(0, n_segments, (batch_size, seq_len))\n",
    "\n",
    "output = embedding_layer(x, seg)\n",
    "print(output.shape)  # Output: [batch_size, seq_len, d_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context shape: torch.Size([2, 4, 8])\n",
      "Attention shape: torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        d_k = Q.size(-1)  # Dimension of the last axis of K\n",
    "        \n",
    "        # Compute scaled attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n",
    "        \n",
    "        # Apply the attention mask\n",
    "        scores.masked_fill(attn_mask, -1e9)\n",
    "        \n",
    "        # Compute attention probabilities\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        \n",
    "        # Compute context using attention probabilities\n",
    "        context = torch.matmul(attn, V)\n",
    "        \n",
    "        return context, attn\n",
    "\n",
    "# Example dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_k = d_v = 8\n",
    "\n",
    "# Input tensors\n",
    "Q = torch.rand(batch_size, seq_len, d_k)  # Query\n",
    "K = torch.rand(batch_size, seq_len, d_k)  # Key\n",
    "V = torch.rand(batch_size, seq_len, d_v)  # Value\n",
    "\n",
    "# Attention mask\n",
    "attn_mask = torch.zeros(batch_size, seq_len, seq_len).bool()\n",
    "\n",
    "# Initialize and run the model\n",
    "attention_layer = ScaledDotProductAttention()\n",
    "context, attn = attention_layer(Q, K, V, attn_mask)\n",
    "\n",
    "print(\"Context shape:\", context.shape)  # Expected: [batch_size, seq_len, d_v]\n",
    "print(\"Attention shape:\", attn.shape)  # Expected: [batch_size, seq_len, seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "        \n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        residual = Q\n",
    "        batch_size = Q.size(0)\n",
    "\n",
    "        # Linear projections and reshaping\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)\n",
    "\n",
    "        # Masking\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        context, attn = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "\n",
    "        # Combine heads and reshape\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.fc(context)\n",
    "\n",
    "        # Add residual connection and layer normalization\n",
    "        return self.layer_norm(output + residual), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 16])\n",
      "Attention weights shape: torch.Size([2, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Example dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 16  # Input feature size\n",
    "n_heads = 4   # Number of attention heads\n",
    "d_k = d_v = 4 # Size of each attention head\n",
    "\n",
    "# Input tensors\n",
    "Q = torch.rand(batch_size, seq_len, d_model)\n",
    "K = torch.rand(batch_size, seq_len, d_model)\n",
    "V = torch.rand(batch_size, seq_len, d_model)\n",
    "attn_mask = torch.zeros(batch_size, seq_len, seq_len).bool()  # No masking\n",
    "\n",
    "# Instantiate and apply MultiHeadAttention\n",
    "multihead_attention = MultiHeadAttention(d_model, n_heads, d_k, d_v)\n",
    "output, attn_weights = multihead_attention(Q, K, V, attn_mask)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # Expected: [batch_size, seq_len, d_model]\n",
    "print(\"Attention weights shape:\", attn_weights.shape)  # Expected: [batch_size, n_heads, seq_len, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 768, 100, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE, D_MODEL, MAX_LEN, N_SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(VOCAB_SIZE, D_MODEL, MAX_LEN, N_SEGMENTS)\n",
    "\n",
    "embedded  = embedding(input_ids, segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = get_attention_pad_masked(input_ids, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attention = MultiHeadAttention(D_MODEL, N_HEADS, D_K, D_V)(embedded, embedded, embedded, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0402,  0.3501,  1.1281,  ..., -0.2291, -2.8916, -0.8162],\n",
       "        [ 0.1645,  1.4837,  0.1231,  ..., -1.9703, -0.6066, -0.2153],\n",
       "        [ 0.0159,  0.9066,  1.4183,  ...,  0.7883, -1.9384, -1.9789],\n",
       "        ...,\n",
       "        [ 1.1938, -0.1854,  1.0648,  ..., -2.1681,  0.3270, -0.6222],\n",
       "        [ 1.1153,  0.6323,  0.8624,  ..., -1.9703, -0.3307, -0.6411],\n",
       "        [ 1.7426,  0.6294, -0.2560,  ..., -0.8645,  0.2386, -1.0920]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, A = multihead_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GELU activation function\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / np.sqrt(2.0)))\n",
    "\n",
    "\n",
    "# Define the Positional Feed Forward Network\n",
    "class PoswiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForward, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "        # self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first linear transformation, GELU activation, second linear transformation\n",
    "        residual = x\n",
    "        x = self.fc2(gelu(self.fc1(x)))\n",
    "        # Add residual connection and apply layer normalization\n",
    "        return x # self.layer_norm(x + residual)\n",
    "\n",
    "\n",
    "# Define the Encoder Layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v, d_ff):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        # Multi-head attention layer\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads, d_k, d_v)\n",
    "        # Positional feed-forward network\n",
    "        self.pos_ffn = PoswiseFeedForward(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        # Apply self-attention\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "        # Apply positional feed-forward network\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Outputs Shape: torch.Size([2, 4, 16])\n",
      "Attention Weights Shape: torch.Size([2, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Example dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 16  # Dimension of input/output embeddings\n",
    "d_ff = 64     # Dimension of feed-forward layer\n",
    "n_heads = 4   # Number of attention heads\n",
    "d_k = d_v = 4 # Dimension of each attention head\n",
    "\n",
    "# Input tensors\n",
    "enc_inputs = torch.rand(batch_size, seq_len, d_model)  # Encoder inputs\n",
    "enc_self_attn_mask = torch.zeros(batch_size, seq_len, seq_len).bool()  # No masking\n",
    "\n",
    "# Instantiate EncoderLayer\n",
    "encoder_layer = EncoderLayer(d_model, n_heads, d_k, d_v, d_ff)\n",
    "\n",
    "# Forward pass through the encoder layer\n",
    "enc_outputs, attn_weights = encoder_layer(enc_inputs, enc_self_attn_mask)\n",
    "\n",
    "print(\"Encoder Outputs Shape:\", enc_outputs.shape)  # Expected: [batch_size, seq_len, d_model]\n",
    "print(\"Attention Weights Shape:\", attn_weights.shape)  # Expected: [batch_size, n_heads, seq_len, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, d_model, n_heads, d_k, d_v, d_ff, n_layers, n_segments):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = Embedding(vocab_size, max_len, d_model, n_segments)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, d_k, d_v, d_ff) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Pooling and classification layers\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ1 = nn.Tanh()\n",
    "\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.activ2 = gelu\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "\n",
    "        # Decoder for masked language modeling (MLM)\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        \n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        # Embedding output\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "\n",
    "        # Attention mask\n",
    "        enc_self_attn_mask = get_attention_pad_masked(input_ids, input_ids)\n",
    "\n",
    "        # Pass through encoder layers\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "\n",
    "        # Pooling for classification\n",
    "        h_pooled = self.activ1(self.fc(output[:, 0]))  # CLS token embedding\n",
    "        logits_clsf = self.classifier(h_pooled)\n",
    "\n",
    "        # Gather masked positions for MLM\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1))\n",
    "        h_masked = torch.gather(output, 1, masked_pos)\n",
    "        h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
    "\n",
    "        # MLM logits\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias\n",
    "\n",
    "        return logits_lm, logits_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 100, 768, 12, 64, 64, 3072, 6, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE, MAX_LEN, D_MODEL, N_HEADS, D_K, D_K, D_FF, N_LAYERS, N_SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 100 # There is something wrong here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "#                 vocab_size, max_len, d_model, n_heads, d_k, d_v, d_ff, n_layers, n_segments\n",
    "bert_model = BERT(VOCAB_SIZE, MAX_LEN, D_MODEL, N_HEADS, D_K, D_V, D_FF, N_LAYERS, N_SEGMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embedding): Embedding(\n",
       "    (tok_embed): Embedding(65, 100)\n",
       "    (pos_embed): Embedding(100, 100)\n",
       "    (seg_embed): Embedding(2, 100)\n",
       "    (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x EncoderLayer(\n",
       "      (enc_self_attn): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=100, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=100, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=100, out_features=768, bias=True)\n",
       "        (fc): Linear(in_features=768, out_features=100, bias=True)\n",
       "        (layer_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): ScaledDotProductAttention()\n",
       "      )\n",
       "      (pos_ffn): PoswiseFeedForward(\n",
       "        (fc1): Linear(in_features=100, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (activ1): Tanh()\n",
       "  (linear): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  (classifier): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (decoder): Linear(in_features=100, out_features=65, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-5): 6 x EncoderLayer(\n",
       "    (enc_self_attn): MultiHeadAttention(\n",
       "      (W_Q): Linear(in_features=100, out_features=768, bias=True)\n",
       "      (W_K): Linear(in_features=100, out_features=768, bias=True)\n",
       "      (W_V): Linear(in_features=100, out_features=768, bias=True)\n",
       "      (fc): Linear(in_features=768, out_features=100, bias=True)\n",
       "      (layer_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): ScaledDotProductAttention()\n",
       "    )\n",
       "    (pos_ffn): PoswiseFeedForward(\n",
       "      (fc1): Linear(in_features=100, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bert_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = create_batches(batch_size=BATCH_SIZE, \n",
    "                       sentences=sentences, \n",
    "                       tokenized_sentences=tokens_lst, \n",
    "                       word_to_num_dict=words_dict, \n",
    "                       num_to_word_dict=nums_dict, \n",
    "                       max_predictable_tokens=MAX_PRED, \n",
    "                       vocab_size=VOCAB_SIZE, \n",
    "                       max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_positions, is_next = map(torch.LongTensor, zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs Shape: torch.Size([6, 100]) 6 100\n",
      "Masked Positions Shape: torch.Size([6, 7])\n",
      "Segment IDs Shape: torch.Size([6, 100]) 6 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input IDs Shape: {input_ids.shape}\", BATCH_SIZE, MAX_LEN)\n",
    "print(f\"Masked Positions Shape: {masked_positions.shape}\")\n",
    "print(f\"Segment IDs Shape: {segment_ids.shape}\", BATCH_SIZE, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6, 100, 100], [6, 12, 100, 100])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[BATCH_SIZE, MAX_LEN, D_MODEL], [BATCH_SIZE, N_HEADS, MAX_LEN, MAX_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([6, 100, 100])\n",
      "Attention weights shape: torch.Size([6, 12, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "# Input tensors\n",
    "Q = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "K = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "V = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "attn_mask = torch.zeros(BATCH_SIZE, MAX_LEN, MAX_LEN).bool()  # No masking\n",
    "\n",
    "# Instantiate and apply MultiHeadAttention\n",
    "multihead_attention = MultiHeadAttention(D_MODEL, N_HEADS, D_K, D_V)\n",
    "output, attn_weights = multihead_attention(Q, K, V, attn_mask)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # Expected: [BATCH_SIZE, MAX_LEN, D_MODEL]\n",
    "print(\"Attention weights shape:\", attn_weights.shape)  # Expected: [BATCH_SIZE, N_HEADS, MAX_LEN, MAX_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits MLM Shape: torch.Size([6, 7, 65])\n",
      "Logits Classification Shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Forward pass\n",
    "logits_lm, logits_clsf = bert_model(input_ids, segment_ids, masked_positions)\n",
    "\n",
    "print(\"Logits MLM Shape:\", logits_lm.shape)  # Expected: [batch_size, num_masked_positions, vocab_size]\n",
    "print(\"Logits Classification Shape:\", logits_clsf.shape)  # Expected: [batch_size, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss 20.6060\n",
      "Epoch: 2 | Loss 10.5539\n",
      "Epoch: 3 | Loss 21.7356\n",
      "Epoch: 4 | Loss 15.7067\n",
      "Epoch: 5 | Loss 11.3841\n",
      "Epoch: 6 | Loss 11.4190\n",
      "Epoch: 7 | Loss 10.1651\n",
      "Epoch: 8 | Loss 8.2136\n",
      "Epoch: 9 | Loss 6.3131\n",
      "Epoch: 10 | Loss 6.3044\n",
      "Epoch: 11 | Loss 6.3839\n",
      "Epoch: 12 | Loss 4.3648\n",
      "Epoch: 13 | Loss 4.1223\n",
      "Epoch: 14 | Loss 4.0361\n",
      "Epoch: 15 | Loss 3.8021\n",
      "Epoch: 16 | Loss 3.8142\n",
      "Epoch: 17 | Loss 4.1228\n",
      "Epoch: 18 | Loss 3.7361\n",
      "Epoch: 19 | Loss 3.5766\n",
      "Epoch: 20 | Loss 3.5544\n",
      "Epoch: 21 | Loss 3.4741\n",
      "Epoch: 22 | Loss 3.3110\n",
      "Epoch: 23 | Loss 3.1811\n",
      "Epoch: 24 | Loss 3.1922\n",
      "Epoch: 25 | Loss 3.2078\n",
      "Epoch: 26 | Loss 3.0766\n",
      "Epoch: 27 | Loss 2.9168\n",
      "Epoch: 28 | Loss 2.8608\n",
      "Epoch: 29 | Loss 2.8399\n",
      "Epoch: 30 | Loss 2.7829\n",
      "Epoch: 31 | Loss 2.6982\n",
      "Epoch: 32 | Loss 2.6395\n",
      "Epoch: 33 | Loss 2.6312\n",
      "Epoch: 34 | Loss 2.6070\n",
      "Epoch: 35 | Loss 2.5346\n",
      "Epoch: 36 | Loss 2.4768\n",
      "Epoch: 37 | Loss 2.4555\n",
      "Epoch: 38 | Loss 2.4354\n",
      "Epoch: 39 | Loss 2.3982\n",
      "Epoch: 40 | Loss 2.3624\n",
      "Epoch: 41 | Loss 2.3492\n",
      "Epoch: 42 | Loss 2.3448\n",
      "Epoch: 43 | Loss 2.3284\n",
      "Epoch: 44 | Loss 2.3118\n",
      "Epoch: 45 | Loss 2.3096\n",
      "Epoch: 46 | Loss 2.3144\n",
      "Epoch: 47 | Loss 2.3122\n",
      "Epoch: 48 | Loss 2.2988\n",
      "Epoch: 49 | Loss 2.2830\n",
      "Epoch: 50 | Loss 2.2771\n",
      "CPU times: user 2min 21s, sys: 871 ms, total: 2min 22s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    logits_lm, logits_clsf = bert_model(input_ids, segment_ids, masked_positions)\n",
    "    \n",
    "\n",
    "    loss_lm = criterion(logits_lm.transpose(1,2), masked_tokens)\n",
    "    loss_lm = (loss_lm.float()).mean()\n",
    "    \n",
    "    loss_clsf = criterion(logits_clsf, is_next)\n",
    "    \n",
    "    loss = loss_lm + loss_clsf\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1} | Loss {loss:.4f}')\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_positions, is_next = map(torch.LongTensor, zip(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 27, 13,  3, 57,  8, 54,  5,  2, 18, 21,  2,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'pode',\n",
       " 'sim',\n",
       " '[MASK]',\n",
       " 'vemos',\n",
       " 'mais',\n",
       " 'vamos',\n",
       " 'então',\n",
       " '[SEP]',\n",
       " 'obrigado',\n",
       " 'camila',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nums_dict[w.item()] for w in input_ids[0] if nums_dict[w.item()] != '[PAD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_lm, logits_clsf = bert_model(input_ids, segment_ids, masked_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_lm = logits_lm.data.max(2)[1][0].data.numpy()\n",
    "logits_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 30]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pos.item() for pos in masked_tokens[0] if pos.item() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pos for pos in logits_lm if pos != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_clsf = logits_clsf.data.max(1)[1].data.numpy()[0]\n",
    "\n",
    "True if is_next else False, True if logits_clsf else False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
