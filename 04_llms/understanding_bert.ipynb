{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"data.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Olá, como vai? Eu sou a Camila.\\n'\n",
      "'Olá, Camila, meu nome é Fernando. Muito prazer.\\n'\n",
      "'Prazer em conhecer você também. Como você está hoje?\\n'\n",
      "'Ótimo. Meu time de futebol venceu a competição.\\n'\n",
      "'Uau, Parabéns Fernando!\\n'\n",
      "'Obrigado Camila.\\n'\n",
      "'Vamos comer uma pizza mais tarde para celebrar?\\n'\n",
      "'Claro. Você recomenda algum restaurante Camila?\\n'\n",
      "'Sim, abriu um restaurante novo e dizem que a pizza de banana é fenomenal.\\n'\n",
      "'Ok. Nos encontramos no restaurante às sete da noite, pode ser?\\n'\n",
      "'Pode sim. Nos vemos mais tarde então.'\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['olá como vai eu sou a camila', 'olá camila meu nome é fernando muito prazer', 'prazer em conhecer você também como você está hoje', 'ótimo meu time de futebol venceu a competição', 'uau parabéns fernando', 'obrigado camila', 'vamos comer uma pizza mais tarde para celebrar', 'claro você recomenda algum restaurante camila', 'sim abriu um restaurante novo e dizem que a pizza de banana é fenomenal', 'ok nos encontramos no restaurante às sete da noite pode ser', 'pode sim nos vemos mais tarde então']\n"
     ]
    }
   ],
   "source": [
    "# re.sub(...) function replaces all occurrences of the characters within the character class with an empty string\n",
    "sentences = re.sub(\"[.,!?\\\\-']\", '', data.lower().replace(\"\\n\", \" \")).split('\\\\n')\n",
    "sentences = [s.strip() for s in sentences]\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conhecer', 'algum', 'e', 'abriu', 'você', 'um', 'prazer', 'que', 'sou', 'dizem', 'pizza', 'time', 'da', 'fenomenal', 'vai', 'parabéns', 'pode', 'vamos', 'nos', 'sim', 'venceu', 'às', 'tarde', 'vemos', 'camila', 'para', 'hoje', 'então', 'mais', 'a', 'ótimo', 'competição', 'eu', 'em', 'ok', 'é', 'encontramos', 'obrigado', 'como', 'celebrar', 'também', 'de', 'banana', 'recomenda', 'uau', 'novo', 'noite', 'muito', 'futebol', 'no', 'sete', 'olá', 'restaurante', 'claro', 'está', 'ser', 'uma', 'meu', 'comer', 'fernando', 'nome']\n"
     ]
    }
   ],
   "source": [
    "words_lst = list( set( \" \".join(sentences).split() ) )\n",
    "\n",
    "print(words_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT special tokens\n",
    "words_dict = {\n",
    "    \"[PAD]\": 0, \n",
    "    \"[CLS]\": 1, \n",
    "    \"[SEP]\": 2, \n",
    "    \"[MASK]\": 3\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(words_lst):\n",
    "    words_dict[w] = i + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, 'conhecer': 4, 'algum': 5, 'e': 6, 'abriu': 7, 'você': 8, 'um': 9, 'prazer': 10, 'que': 11, 'sou': 12, 'dizem': 13, 'pizza': 14, 'time': 15, 'da': 16, 'fenomenal': 17, 'vai': 18, 'parabéns': 19, 'pode': 20, 'vamos': 21, 'nos': 22, 'sim': 23, 'venceu': 24, 'às': 25, 'tarde': 26, 'vemos': 27, 'camila': 28, 'para': 29, 'hoje': 30, 'então': 31, 'mais': 32, 'a': 33, 'ótimo': 34, 'competição': 35, 'eu': 36, 'em': 37, 'ok': 38, 'é': 39, 'encontramos': 40, 'obrigado': 41, 'como': 42, 'celebrar': 43, 'também': 44, 'de': 45, 'banana': 46, 'recomenda': 47, 'uau': 48, 'novo': 49, 'noite': 50, 'muito': 51, 'futebol': 52, 'no': 53, 'sete': 54, 'olá': 55, 'restaurante': 56, 'claro': 57, 'está': 58, 'ser': 59, 'uma': 60, 'meu': 61, 'comer': 62, 'fernando': 63, 'nome': 64}\n"
     ]
    }
   ],
   "source": [
    "print(words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '[PAD]', 1: '[CLS]', 2: '[SEP]', 3: '[MASK]', 4: 'conhecer', 5: 'algum', 6: 'e', 7: 'abriu', 8: 'você', 9: 'um', 10: 'prazer', 11: 'que', 12: 'sou', 13: 'dizem', 14: 'pizza', 15: 'time', 16: 'da', 17: 'fenomenal', 18: 'vai', 19: 'parabéns', 20: 'pode', 21: 'vamos', 22: 'nos', 23: 'sim', 24: 'venceu', 25: 'às', 26: 'tarde', 27: 'vemos', 28: 'camila', 29: 'para', 30: 'hoje', 31: 'então', 32: 'mais', 33: 'a', 34: 'ótimo', 35: 'competição', 36: 'eu', 37: 'em', 38: 'ok', 39: 'é', 40: 'encontramos', 41: 'obrigado', 42: 'como', 43: 'celebrar', 44: 'também', 45: 'de', 46: 'banana', 47: 'recomenda', 48: 'uau', 49: 'novo', 50: 'noite', 51: 'muito', 52: 'futebol', 53: 'no', 54: 'sete', 55: 'olá', 56: 'restaurante', 57: 'claro', 58: 'está', 59: 'ser', 60: 'uma', 61: 'meu', 62: 'comer', 63: 'fernando', 64: 'nome'}\n"
     ]
    }
   ],
   "source": [
    "nums_dict = { i: k for k, i in words_dict.items()}\n",
    "\n",
    "print(nums_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(words_dict)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olá', 'como', 'vai', 'eu', 'sou', 'a', 'camila']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lst = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = [words_dict[s] for s in sentence.split()]\n",
    "    tokens_lst.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[55, 42, 18, 36, 12, 33, 28],\n",
       " [55, 28, 61, 64, 39, 63, 51, 10],\n",
       " [10, 37, 4, 8, 44, 42, 8, 58, 30],\n",
       " [34, 61, 15, 45, 52, 24, 33, 35],\n",
       " [48, 19, 63],\n",
       " [41, 28],\n",
       " [21, 62, 60, 14, 32, 26, 29, 43],\n",
       " [57, 8, 47, 5, 56, 28],\n",
       " [23, 7, 9, 56, 49, 6, 13, 11, 33, 14, 45, 46, 39, 17],\n",
       " [38, 22, 40, 53, 56, 25, 54, 16, 50, 20, 59],\n",
       " [20, 23, 22, 27, 32, 26, 31]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparams definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "N_SEGMENTS = 2\n",
    "DROPOUT    = 0.2\n",
    "\n",
    "MAX_LEN     = 100\n",
    "MAX_PRED    = 7 # max num of tokens that will be predicted \n",
    "\n",
    "N_LAYERS    = 6\n",
    "N_HEADS     = 12\n",
    "\n",
    "D_MODEL     = 768 # embedding dim\n",
    "D_FF        = D_MODEL * 4 # feedforward dim\n",
    "D_K = D_V   = 64\n",
    "\n",
    "N_EPOCHS    = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olá como vai eu sou a camila',\n",
       " 'olá camila meu nome é fernando muito prazer',\n",
       " 'prazer em conhecer você também como você está hoje',\n",
       " 'ótimo meu time de futebol venceu a competição',\n",
       " 'uau parabéns fernando',\n",
       " 'obrigado camila',\n",
       " 'vamos comer uma pizza mais tarde para celebrar',\n",
       " 'claro você recomenda algum restaurante camila',\n",
       " 'sim abriu um restaurante novo e dizem que a pizza de banana é fenomenal',\n",
       " 'ok nos encontramos no restaurante às sete da noite pode ser',\n",
       " 'pode sim nos vemos mais tarde então']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = randrange(len(sentences)), randrange(len(sentences))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([38, 22, 40, 53, 56, 25, 54, 16, 50, 20, 59], [55, 42, 18, 36, 12, 33, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa, bb = tokens_lst[a], tokens_lst[b]\n",
    "aa, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 38,\n",
       " 22,\n",
       " 40,\n",
       " 53,\n",
       " 56,\n",
       " 25,\n",
       " 54,\n",
       " 16,\n",
       " 50,\n",
       " 20,\n",
       " 59,\n",
       " 2,\n",
       " 55,\n",
       " 42,\n",
       " 18,\n",
       " 36,\n",
       " 12,\n",
       " 33,\n",
       " 28,\n",
       " 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = [words_dict[\"[CLS]\"]] + aa + [words_dict[\"[SEP]\"]] + bb + [words_dict[\"[SEP]\"]]\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_ids = [0] * (1 + len(aa) + 1) + [1] * (len(bb) + 1)\n",
    "segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(MAX_PRED, max(1, int(round(len(input_ids) * 0.15)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_position_candidates = [i for i, token in enumerate(input_ids) if token != words_dict[\"[CLS]\"] and token != words_dict[\"[SEP]\"]]\n",
    "mask_position_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(batch_size, sentences, tokenized_sentences, word_to_num_dict, num_to_word_dict, max_predictable_tokens, vocab_size, max_len):\n",
    "\n",
    "    batch = []\n",
    "    \n",
    "    positive = negative = 0\n",
    "\n",
    "    while (positive != batch_size/2) or (negative != batch_size/2):\n",
    "\n",
    "        tokens_a_index, tokens_b_index = randrange(len(sentences)), randrange(len(sentences))\n",
    "        tokens_a, tokens_b = tokenized_sentences[tokens_a_index], tokenized_sentences[tokens_b_index]\n",
    "\n",
    "        input_ids = [word_to_num_dict[\"[CLS]\"]] + tokens_a + [word_to_num_dict[\"[SEP]\"]] + tokens_b + [word_to_num_dict[\"[SEP]\"]]\n",
    "        segment_ids = segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        n_pred =  min(max_predictable_tokens, max(1, int(round(len(input_ids) * 0.15)))) \n",
    "\n",
    "        mask_position_candidates = [i for i, token in enumerate(input_ids) if token != word_to_num_dict[\"[CLS]\"] and token != word_to_num_dict[\"[SEP]\"]]\n",
    "        shuffle(mask_position_candidates)\n",
    "\n",
    "        masked_tokens, masked_positions = [], []\n",
    "        for pos in mask_position_candidates[:n_pred]:\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            masked_positions.append(pos)\n",
    "            \n",
    "            if random() < 0.8:\n",
    "                input_ids[pos] = word_to_num_dict[\"[MASK]\"]\n",
    "            elif random() < 0.5:\n",
    "                index = randint(0, vocab_size - 1)\n",
    "                input_ids[pos] = word_to_num_dict[num_to_word_dict[index]]\n",
    "\n",
    "        padding = max_len - len(input_ids)\n",
    "        input_ids.extend([0] * padding)\n",
    "        segment_ids.extend([0] * padding)\n",
    "\n",
    "        if max_predictable_tokens > n_pred:\n",
    "            padding = max_predictable_tokens - n_pred\n",
    "            masked_tokens.extend([0] * padding)\n",
    "            masked_positions.extend([0] * padding) \n",
    "\n",
    "        if (tokens_a_index + 1 == tokens_b_index) and (positive < batch_size / 2):\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_positions, True])\n",
    "            positive += 1\n",
    "\n",
    "        elif (tokens_a_index + 1 != tokens_b_index) and (negative < batch_size / 2):\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_positions, False])\n",
    "            negative += 1\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 6\n",
    "# N_SEGMENTS = 2\n",
    "# DROPOUT    = 0.2\n",
    "\n",
    "# MAX_LEN     = 100\n",
    "# MAX_PRED    = 7 # max num of tokens that will be predicted \n",
    "\n",
    "# N_LAYERS    = 6\n",
    "# N_HEADS     = 12\n",
    "\n",
    "# D_MODEL     = 768 # embedding dim\n",
    "# D_FF        = D_MODEL * 4 # feedforward dim\n",
    "# D_K = D_V   = 64\n",
    "\n",
    "# N_EPOCHS    = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "\n",
    "# d1 = OrderedDict(sorted(nums_dict.items()))\n",
    "# print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = create_batches(batch_size=BATCH_SIZE, \n",
    "                       sentences=sentences, \n",
    "                       tokenized_sentences=tokens_lst, \n",
    "                       word_to_num_dict=words_dict, \n",
    "                       num_to_word_dict=nums_dict, \n",
    "                       max_predictable_tokens=MAX_PRED, \n",
    "                       vocab_size=VOCAB_SIZE, \n",
    "                       max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_positions, is_next = map(torch.LongTensor, zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 21, 62, 60, 14, 32,  3,  3, 43,  2, 57,  8, 47,  5, 56, 28,  2,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([62, 26, 29,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 7, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_next[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_pad_masked(query_sequence, key_sequence):\n",
    "    \n",
    "    batch_size, len_q = query_sequence.size()\n",
    "    batch_size, len_k = key_sequence.size()\n",
    "    \n",
    "    pad_attn_masked = key_sequence.data.eq(0).unsqueeze(1)\n",
    "    \n",
    "    return pad_attn_masked.expand(batch_size, len_q, len_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 21, 62, 60, 14, 32,  3,  3, 43,  2, 57,  8, 47,  5, 56, 28,  2,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attention_pad_masked(input_ids, input_ids)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len, n_segments):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        # print(\"...forward step\")\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)\n",
    "\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "max_len = 100\n",
    "n_segments = 2\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, d_model, max_len, n_segments)\n",
    "\n",
    "# Input example\n",
    "batch_size = 32\n",
    "seq_len = 20\n",
    "x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "seg = torch.randint(0, n_segments, (batch_size, seq_len))\n",
    "\n",
    "output = embedding_layer(x, seg)\n",
    "print(output.shape)  # Output: [batch_size, seq_len, d_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context shape: torch.Size([2, 4, 8])\n",
      "Attention shape: torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        d_k = Q.size(-1)  # Dimension of the last axis of K\n",
    "        \n",
    "        # Compute scaled attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n",
    "        \n",
    "        # Apply the attention mask\n",
    "        scores.masked_fill(attn_mask, -1e9)\n",
    "        \n",
    "        # Compute attention probabilities\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        \n",
    "        # Compute context using attention probabilities\n",
    "        context = torch.matmul(attn, V)\n",
    "        \n",
    "        return context, attn\n",
    "\n",
    "# Example dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_k = d_v = 8\n",
    "\n",
    "# Input tensors\n",
    "Q = torch.rand(batch_size, seq_len, d_k)  # Query\n",
    "K = torch.rand(batch_size, seq_len, d_k)  # Key\n",
    "V = torch.rand(batch_size, seq_len, d_v)  # Value\n",
    "\n",
    "# Attention mask\n",
    "attn_mask = torch.zeros(batch_size, seq_len, seq_len).bool()\n",
    "\n",
    "# Initialize and run the model\n",
    "attention_layer = ScaledDotProductAttention()\n",
    "context, attn = attention_layer(Q, K, V, attn_mask)\n",
    "\n",
    "print(\"Context shape:\", context.shape)  # Expected: [batch_size, seq_len, d_v]\n",
    "print(\"Attention shape:\", attn.shape)  # Expected: [batch_size, seq_len, seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "        \n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        residual = Q\n",
    "        batch_size = Q.size(0)\n",
    "\n",
    "        # Linear projections and reshaping\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)\n",
    "\n",
    "        # Masking\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        context, attn = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "\n",
    "        # Combine heads and reshape\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.fc(context)\n",
    "\n",
    "        # Add residual connection and layer normalization\n",
    "        return self.layer_norm(output + residual), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 16])\n",
      "Attention weights shape: torch.Size([2, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Example dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 16  # Input feature size\n",
    "n_heads = 4   # Number of attention heads\n",
    "d_k = d_v = 4 # Size of each attention head\n",
    "\n",
    "# Input tensors\n",
    "Q = torch.rand(batch_size, seq_len, d_model)\n",
    "K = torch.rand(batch_size, seq_len, d_model)\n",
    "V = torch.rand(batch_size, seq_len, d_model)\n",
    "attn_mask = torch.zeros(batch_size, seq_len, seq_len).bool()  # No masking\n",
    "\n",
    "# Instantiate and apply MultiHeadAttention\n",
    "multihead_attention = MultiHeadAttention(d_model, n_heads, d_k, d_v)\n",
    "output, attn_weights = multihead_attention(Q, K, V, attn_mask)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # Expected: [batch_size, seq_len, d_model]\n",
    "print(\"Attention weights shape:\", attn_weights.shape)  # Expected: [batch_size, n_heads, seq_len, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 768, 100, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE, D_MODEL, MAX_LEN, N_SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(VOCAB_SIZE, D_MODEL, MAX_LEN, N_SEGMENTS)\n",
    "\n",
    "embedded  = embedding(input_ids, segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = get_attention_pad_masked(input_ids, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attention = MultiHeadAttention(D_MODEL, N_HEADS, D_K, D_V)(embedded, embedded, embedded, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8016, -0.7674, -0.6850,  ..., -0.3848, -0.7357, -0.9320],\n",
       "        [ 0.5090,  0.3723,  0.2620,  ...,  1.2269, -0.2860, -0.7234],\n",
       "        [ 0.9513, -0.3783, -0.3725,  ...,  0.1868, -0.0491, -0.2502],\n",
       "        ...,\n",
       "        [-0.8316,  0.4293, -0.7776,  ..., -0.5132,  1.6908, -0.1155],\n",
       "        [-1.1358,  0.5712, -0.8526,  ..., -0.2703,  1.4036, -0.4805],\n",
       "        [-0.9678,  0.1488, -0.5751,  ..., -0.4267,  1.2869, -0.2497]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, A = multihead_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GELU activation function\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / np.sqrt(2.0)))\n",
    "\n",
    "\n",
    "# Define the Positional Feed Forward Network\n",
    "class PoswiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForward, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "        # self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first linear transformation, GELU activation, second linear transformation\n",
    "        residual = x\n",
    "        x = self.fc2(gelu(self.fc1(x)))\n",
    "        # Add residual connection and apply layer normalization\n",
    "        return x # self.layer_norm(x + residual)\n",
    "\n",
    "\n",
    "# Define the Encoder Layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v, d_ff):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        # Multi-head attention layer\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads, d_k, d_v)\n",
    "        # Positional feed-forward network\n",
    "        self.pos_ffn = PoswiseFeedForward(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        # Apply self-attention\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "        # Apply positional feed-forward network\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Outputs Shape: torch.Size([2, 4, 16])\n",
      "Attention Weights Shape: torch.Size([2, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Example dimensions\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 16  # Dimension of input/output embeddings\n",
    "d_ff = 64     # Dimension of feed-forward layer\n",
    "n_heads = 4   # Number of attention heads\n",
    "d_k = d_v = 4 # Dimension of each attention head\n",
    "\n",
    "# Input tensors\n",
    "enc_inputs = torch.rand(batch_size, seq_len, d_model)  # Encoder inputs\n",
    "enc_self_attn_mask = torch.zeros(batch_size, seq_len, seq_len).bool()  # No masking\n",
    "\n",
    "# Instantiate EncoderLayer\n",
    "encoder_layer = EncoderLayer(d_model, n_heads, d_k, d_v, d_ff)\n",
    "\n",
    "# Forward pass through the encoder layer\n",
    "enc_outputs, attn_weights = encoder_layer(enc_inputs, enc_self_attn_mask)\n",
    "\n",
    "print(\"Encoder Outputs Shape:\", enc_outputs.shape)  # Expected: [batch_size, seq_len, d_model]\n",
    "print(\"Attention Weights Shape:\", attn_weights.shape)  # Expected: [batch_size, n_heads, seq_len, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, d_model, n_heads, d_k, d_v, d_ff, n_layers, n_segments):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = Embedding(vocab_size, max_len, d_model, n_segments)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, d_k, d_v, d_ff) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Pooling and classification layers\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ1 = nn.Tanh()\n",
    "\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.activ2 = gelu\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "\n",
    "        # Decoder for masked language modeling (MLM)\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        \n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        # Embedding output\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "\n",
    "        # Attention mask\n",
    "        enc_self_attn_mask = get_attention_pad_masked(input_ids, input_ids)\n",
    "\n",
    "        # Pass through encoder layers\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "\n",
    "        # Pooling for classification\n",
    "        h_pooled = self.activ1(self.fc(output[:, 0]))  # CLS token embedding\n",
    "        logits_clsf = self.classifier(h_pooled)\n",
    "\n",
    "        # Gather masked positions for MLM\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1))\n",
    "        h_masked = torch.gather(output, 1, masked_pos)\n",
    "        h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
    "\n",
    "        # MLM logits\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias\n",
    "\n",
    "        return logits_lm, logits_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 100, 768, 12, 64, 64, 3072, 6, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE, MAX_LEN, D_MODEL, N_HEADS, D_K, D_K, D_FF, N_LAYERS, N_SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "bert_model = BERT(VOCAB_SIZE, MAX_LEN, D_MODEL, N_HEADS, D_K, D_K, D_FF, N_LAYERS, N_SEGMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embedding): Embedding(\n",
       "    (tok_embed): Embedding(65, 100)\n",
       "    (pos_embed): Embedding(768, 100)\n",
       "    (seg_embed): Embedding(2, 100)\n",
       "    (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x EncoderLayer(\n",
       "      (enc_self_attn): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): ScaledDotProductAttention()\n",
       "      )\n",
       "      (pos_ffn): PoswiseFeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activ1): Tanh()\n",
       "  (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (decoder): Linear(in_features=100, out_features=65, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bert_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = create_batches(batch_size=BATCH_SIZE, \n",
    "                       sentences=sentences, \n",
    "                       tokenized_sentences=tokens_lst, \n",
    "                       word_to_num_dict=words_dict, \n",
    "                       num_to_word_dict=nums_dict, \n",
    "                       max_predictable_tokens=MAX_PRED, \n",
    "                       vocab_size=VOCAB_SIZE, \n",
    "                       max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_positions, is_next = map(torch.LongTensor, zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs Shape: torch.Size([6, 100]) 6 100\n",
      "Masked Positions Shape: torch.Size([6, 7])\n",
      "Segment IDs Shape: torch.Size([6, 100]) 6 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input IDs Shape: {input_ids.shape}\", BATCH_SIZE, MAX_LEN)\n",
    "print(f\"Masked Positions Shape: {masked_positions.shape}\")\n",
    "print(f\"Segment IDs Shape: {segment_ids.shape}\", BATCH_SIZE, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6, 100, 768], [6, 12, 100, 100])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[BATCH_SIZE, MAX_LEN, D_MODEL], [BATCH_SIZE, N_HEADS, MAX_LEN, MAX_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([6, 100, 768])\n",
      "Attention weights shape: torch.Size([6, 12, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "# Input tensors\n",
    "Q = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "K = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "V = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "attn_mask = torch.zeros(BATCH_SIZE, MAX_LEN, MAX_LEN).bool()  # No masking\n",
    "\n",
    "# Instantiate and apply MultiHeadAttention\n",
    "multihead_attention = MultiHeadAttention(D_MODEL, N_HEADS, D_K, D_V)\n",
    "output, attn_weights = multihead_attention(Q, K, V, attn_mask)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # Expected: [BATCH_SIZE, MAX_LEN, D_MODEL]\n",
    "print(\"Attention weights shape:\", attn_weights.shape)  # Expected: [BATCH_SIZE, N_HEADS, MAX_LEN, MAX_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forward pass\n",
    "logits_lm, logits_clsf = bert_model(input_ids, segment_ids, masked_positions)\n",
    "\n",
    "print(\"Logits MLM Shape:\", logits_lm.shape)  # Expected: [batch_size, num_masked_positions, vocab_size]\n",
    "print(\"Logits Classification Shape:\", logits_clsf.shape)  # Expected: [batch_size, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
